Using python3, using a virtual environment 
(e.g. ~jbellinger/archivemonitor/venv)

UPDATE:  I'm switching over to doing things the python way,
and I created a Utils.py file that is imported by the
GlueLTA.py program.  I'll retrofit other stuff later.

Since each of these python scripts (except NERSC_Client)
was meant to run in a single instance on a single machine,
in a single thread of Step1 Step2 Step3 etc, I wrote
the python without using objects.

HISTORICAL NOTE:  I was pointed to the mod_wsgi framework
for using the REST server.  However, it wasn't obvious
what to use for communication, so I expanded the initial
curl test scripts to handle the interactions.  These are
ugly as home-made sin, and at some point I'd like to get
rid of them in favor of something more bulletproof--and
maybe with some authentication.  Patrick has some things
that would probably work.
Because the object was to get something running quickly,
and get stuff to NERSC before we got too far behind the
eight-ball, this does not (yet) use any of the file catalog
or Patrick's (new) REST framework.
In the medium term, the only things I expect to use are
the dumper/DumpControl.py and the jadetools/GlueLTA.py
(and the Utils.py)
In the long term, DumpControl and GlueLTA will probably
have to be more tightly integrated into the LTA suite.



The only module in this directory that hasn't been
migrated to proper import syntax is BundleScanner.py,
and I'll be moving that one as soon as the test works.

I wanted to maintain consistency between chunks of code, so the utility
code is in the import files
IMPORT_db.py	For mysql accesses
IMPORT_utils.py For everything else
and the codebase that I want to keep the same everywhere is in
CODE_db.py	For mysql access
CODE_utils.py	For everything else

The preprocessor is
preproc.py
e.g.
python preproc.py BundleScanner.py.base
 creates BundleScanner.py

The advantages to using this rather than a local environment are
ease of setup at the remote sites (e.g. I only need a single 
python file at NERSC), and more readable code.  In practice this 
doesn't matter enough to keep it, and I'll be changing it to
use python include's.  Nice try.

BundleScanner.py
  This runs on jade-lta, and handles bundles appearing that
   need to be shipped to NERSC.

TrainOK.sh
  This will be (in progress) a tool to tell what the overall
   chain of operations looks like.  Right now it simply checks
   the to-NERSC pipeline, and determines how much space the
   to-NERSC buffer has.  Later this will include the processing
   space, the dump space, and any info from NERSC we think useful
   It talks to nagios/check_mk

Command.py
   Tell the to-NERSC pipeline to Run or Halt or Drain

Dirinfo.py
   Tell me about what bundles are associated with what directories
    in the rest DB

ManualBundle.py
   Delete bundles that have gone to NERSC safely.  This will be
    integrated into BundleScanner.

ManualFiles.py
   Delete the files that went into the bundles that went to NERSC
    safely.  Run after ManualBundle.  This will NOT be integrated
    into anything else until I have a solid handle on what will
    be kept in warehouse and what won't, and some authentication
    in the REST server--i.e. probably never.

Monitoring.py
   Tell what's going on with the to-NERSC pipeline.  E.g.
NERSCStatus=   Run |  | 48420 | 2019-11-21 13:31:03  7
NERSCToken=   NULL at 2019-11-21 13:31:04  7
LocalStatus=   Run |  | 349397 | 2019-11-21 13:10:01  28
BundleStatusCounts=    | Untouched:0 | JsonMade:0 | PushProblem:0 | PushDone:0 | NERSCRunning:0 | NERSCDone:0 | NERSCProblem:0 | NERSCClean:5 | LocalDeleted:90 | LocalFilesDeleted:406 | Abort:123 | Retry:0
Duplicate bundle transfers=  33.0

