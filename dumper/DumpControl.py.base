# DumpControl.py.base
import sys
#SUPERIMPORT IMPORT_utils.py
#
##SUPERIMPORT CODE_utils.py

##########
# Utilities:
#  1) Check a slot
#    a) Is it readable?
#    b) What is its UUID?  The .json file tells us
#    c) Get the wanted trees and parse for the top directories
#    d) Organize the groups by top directory
#    e) Look in those top directories to find the year(s) for each
#    f) Use those lists and those years to create a new list of
#       rsync sources, and return this and the UUID
#  2) Create a rsync bash script using the UUID and rsync sources
#    a) New file w/ UUID.sh name and a list
#    b) Submit this (do I want the process ID too?)



#################################################################
# INVENTORY CODE
#
###
# Give top directories from a list
def GiveTops(desiredtrees):
    if len(desiredtrees) <= 0:
        return []
    toplist = []
    for tree in desiredtrees:
        tip = tree.split('/')[0]
        if tip not in toplist:
            toplist.append(tip)
    return toplist

###
# Return the target directory for copying "to"
def GiveTarget():
    gtgeturl = copy.deepcopy(basicgeturl)
    gtgeturl.append(targetdumpingdumptarget)
    gtoutp, gterro, gtcode = getoutputerrorsimplecommand(gtgeturl, 1)
    if int(gtcode) != 0 or 'FAILURE' in str(gtoutp):
        print('Get Target directory failed', gtoutp)
        sys.exit(0)
    dump_json = json.loads(singletodouble(gtoutp))
    try:
        directory = dump_json[0]['target']
    except:
        print('Cannot unpack', dump_json)
        sys.exit(0)
    return directory

###
#  Count the number of files in the specified directory and compare
#   with the expected number
def CountFilesInDir(cfidname, cfidexpectedcount):
    cfidcommand = ['/bin/ls', cfidname]
    cfidoutp, cfiderro, cfidcode = getoutputerrorsimplecommand(cfidcommand, 1)
    if int(cfidcode) != 0:
        print('CountFilesInDir failed to see', cfidname, cfiderro)
        sys.exit(0)
    #
    return len(cfidoutp.split()) == cfidexpectedcount

####
# Return the subdirectory names

###
# Inventory a slot.  Pass it the json for the slot (has old info)
# and the list of trees we want to archive.  YEAR must be
# replaced with the actual year(s) found
def InventoryOneFull(slotlocation):
    # First find out what trees we want to read
    i1geturl = copy.deepcopy(basicgeturl)
    i1geturl.append(targetdumpingwantedtrees)
    i1outp, i1erro, i1code = getoutputerrorsimplecommand(i1geturl, 1)
    if int(i1code) != 0 or 'FAILURE' in str(i1outp):
        print('Get trees failure', i1geturl, i1outp)
        sys.exit(0)
    desiredtrees = []
    my_json = json.loads(singletodouble(i1outp))
    for js in my_json:
        h = js['dataTree']
        desiredtrees.append(h)

    #
    # If no trees to read, why bother?
    if len(desiredtrees) <= 0:
        return []
    #
    toplist = GiveTops(desiredtrees)
    #
    # Note that even if the disk is not mounted, the mountpoint
    #  is still there, and will be "readable" if not populated
    # Bail if it is empty--probably not mounted
    #
    command = ['/bin/ls', slotlocation]
    i2outp, i2erro, i2code = getoutputerrorsimplecommand(command, 1)
    if int(i2code) != 0 or len(i2outp) <= 1:
        print('Cannot read the disk in', slotlocation)
        return []	# Do I want to set an error?
    answer = str(i2outp)
    for toplevel in answer.split():
        #print(toplevel)
        if len(toplevel.split('-')) == 5:
            diskuuid = toplevel
    #
    # Generate the list of directories to rsync
    dirstoscan = []
    for tip in toplist:
        if tip in answer.split():
            command = ['/bin/ls', slotlocation + '/' + tip]
            i3outp, i3erro, i3code = getoutputerrorsimplecommand(command, 1)
            if int(i3code) != 0:
                continue	# May not be present, do not worry about it
            tipyearlist = []
            for y in i3outp.split():
                tipyearlist.append(y)
            for dt in desiredtrees:
                if tip in dt:
                    words = dt.split('YEAR')
                    for y in tipyearlist:
                        dirstoscan.append(words[0] + y + words[1])
    #for j in dirstoscan:
    #    print(j)
    return [diskuuid, dirstoscan]

####
# Get the UUID, if this is readable, for use with slot
# management
def InventoryOne(slotlocation):
    #
    command = ['/bin/ls', slotlocation]
    i1outp, i1erro, i1code = getoutputerrorsimplecommand(command, 1)
    if int(i1code) != 0 or len(i1outp) <= 1:
        print('Cannot read the disk in', slotlocation)
        return []	# Do I want to set an error?
    answer = str(i1outp)
    diskuuid = ''
    for toplevel in answer.split():
        #print(toplevel)
        if len(toplevel.split('-')) == 5:
            diskuuid = toplevel
    return diskuuid


####
# Go through all the slots and see what the UUID is in them
# Connect information between SlotContents and PoleDisk
#  entries
def InventoryAll():
    i1geturl = copy.deepcopy(basicgeturl)
    i1geturl.append(targetdumpingslotcontents)
    i1outp, i1erro, i1code = getoutputerrorsimplecommand(i1geturl, 1)
    if int(i1code) != 0:
        print('SlotContents failure', i1geturl, i1outp)
        sys.exit(0)
    my_json = json.loads(singletodouble(i1outp))
    i1geturl = copy.deepcopy(basicgeturl)
    i1geturl.append(targetdumpingdumptarget)
    i1outp, i1erro, i1code = getoutputerrorsimplecommand(i1geturl, 1)
    if int(i1code) != 0 or 'FAILURE' in str(i1outp):
        print('get dump target failure', i1geturl, i1outp)
        sys.exit(0)
    targetarea = str(i1outp)
    #
    for js in my_json:
        # First check if the slot is disabled
        if js['poledisk_id'] < 0:
            continue
        # Now inventory the slot--get the UUID of the disk, if available
        diskuuid = InventoryOne(js['name'])
        if diskuuid == '':
            print('Got nothing for', js['slotnumber'])
            continue
        #
        # Link SlotContents to the new PoleDisk
        stuffforpd = {"diskuuid":diskuuid, "slotnumber":js['slotnumber'], "targetArea":targetarea, "status":"Inventoried"}
        i1posturl = copy.deepcopy(basicposturl)
        i1posturl.append(targetdumpingsetslotcontents + urllib.parse.urlencode(stuffforpd))
        i2outp, i2erro, i2code = getoutputerrorsimplecommand(i1posturl, 1)
        if int(i2code) != 0 or 'FAILURE' in str(i2outp):
            print('Load new PoleDisk failed', i1posturl, i2outp, i2erro, i2code)
            sys.exit(0)
        #
        # OK, now I want to read back what I wrote so I get the new poledisk_id
        i2geturl = copy.deepcopy(basicgeturl)
        i2geturl.append(targetdumpingpolediskuuid + mangle(diskuuid))
        i2outp, i2erro, i2code = getoutputerrorsimplecommand(i2geturl, 1)
        if len(i2outp) == 0 or 'FAILURE' in str(i2outp):
            print('Retrive PoleDisk info failed', i2geturl, i2outp, i2erro, i2code)
            sys.exit(0)
        soutp = i2outp
        try:
            djson = json.loads(singletodouble(soutp))
            js = djson[0]
            case = mangle(str(js['slotnumber']) + ' ' + str(js['poledisk_id']))
        except:
            print('Retrieve of new poledisk_id failed', soutp)
            sys.exit(0)
        #
        # Armed w/ the new poledisk_id, update the slot contents
        i2posturl = copy.deepcopy(basicposturl)
        i2posturl.append(targetdumpingsetslotcontents + case)
        i2outp, i2erro, i2code = getoutputerrorsimplecommand(i2posturl, 1)
        if len(i2outp) != 0 or 'FAILURE' in str(i2outp):
            print('Update SlotContents info failed', i2posturl, i2outp)
            sys.exit(0)

    return

#########################################################
# JOB CHECK CODE
def JobInspectAll():
    # First get a list of all the nominally active slots
    jigeturl = copy.deepcopy(basicgeturl)
    jigeturl.append(targetdumpinggetactive)
    jioutp, jierro, jicode = getoutputerrorsimplecommand(jigeturl, 1)
    if int(jicode) != 0:
        print('JobInspectAll: active slots check failure', jigeturl, jioutp)
        sys.exit(0)
    try:
        my_json = json.loads(singletodouble(jioutp))
    except:
        print('JobInspectAll:  cannot parse ', jioutp)
        sys.exit(0)
    # Load the relevant info up:
    expected = []
    for js in my_json:
        expected.append([js['diskuuid'], js['slotnumber'], js['dateBegun'], js['poledisk_id'], js['name']])
    # Suppose expected is empty and the list of jobs isn't?
    # Flag an error
    #
    #  I expect that the active slot info will be a superset
    #  of the jobs found.  If they match, and the count is
    #  equal to or higher than DUMPING_LIMIT,
    #  don't bother doing anything.
    #  Inspecting the dateBegun vs today might be useful, though
    #
    # Now find out what jobs are active
    #commandj = ['/usr/bin/ps', 'aux']
    commandj = ['/bin/ps', 'aux']
    listing, jerro, jcode = getoutputerrorsimplecommand(commandj, 1)
    if int(jcode) != 0:
        print('JobInspectAll: pstree failed', joutp, jerro, jcode)
        sys.exit(0)
    candidate = []
    wlisting = listing.split()
    for line in wlisting:
        if 'DUMPING' in line:
            candidate.append(line)
    # Inspect if the expected jobs are still running
    matching = []
    notmatched = []
    for v in expected:
        found = False
        for c in candidate:
            if v[0] in c:	# The uuid.  Will there be truncation?
                matching.append(v)
                found = True
                continue
        if not found:
            notmatched.append(v)
    # expected = DB query says these may be still active
    # candidate = jobs actively running
    # matching = jobs running that are in DB
    # notmached = jobs not running that are in DB (=done?)
    return expected, candidate, matching, notmatched

####
# Check if the log space is getting full
def CheckLogSpace():
    #commandc = ['/usr/bin/df', '-h', DUMPING_LOG_SPACE]
    commandc = ['/bin/df', '-h', DUMPING_LOG_SPACE]
    coutp, cerro, ccode = getoutputerrorsimplecommand(commandc, 1)
    if int(ccode) != 0:
        print('CheckLogSpace failed', coutp, cerro, ccode, DUMPING_LOG_SPACE)
        sys.exit(0)
    percent = int(coutp.split()[-2].split('%')[0])
    return percent < 90

####
# Flag completed jobs as needed.  Sanity checking
def JobDecisionCompleted(notmatched):
    # Look for completed jobs and flag them
    # First sanity check
    donelist = []
    if len(notmatched) == 0:
        return donelist
    #
    for jdone in notmatched:
        # First make sure nothing is wrong
        # I expect a script in DUMPING_LOG_SPACE/DUMPING_${UUID} and a log file
        # in DUMPING_LOG_SPACE/DUMPING_${UUID}.log
        jid = jdone[3]
        tentative = DUMPING_LOG_SPACE + 'DUMPING_' + jdone[0] + '.log'
        commandj = ['/usr/bin/tail', '-n1', tentative]
        answerline, jerro, jcode = getoutputerrorsimplecommand(commandj, 1)
        if int(jcode) != 0:
            print('JobDecisionCompleted failed to tail', tentative, 'X')
            sys.exit(0)
        #
        # If the file is still empty, presumably it is not yet done
        if len(answerline) == 0:
            continue
        #
        # Sanity checking--expect "SUMMARY 5 5" or however many rsyncs were done
        summaryinfo = answerline.split()
        if summaryinfo[0] != 'SUMMARY':
            continue
        try:
            numtried = int(summaryinfo[1])
            numsucceeded = int(summaryinfo[2])
        except:
            print('JobDecisionCompleted summary info line corrupt for', tentative, summaryinfo)
            print('It may have crashed.  Rerun the rsync?', answerline, 'X')
            sys.exit(0)
        if numtried != numsucceeded:
            print('JobDecisionCompleted summary line info shows problems for', tentative, summaryinfo)
            print('Rerun the rsync?', answerline, 'X')
            sys.exit(0)
        jdposturl = copy.deepcopy(basicposturl)
        jdposturl.append(targetdumpingpolediskdone + mangle(str(jid)))
        jdoutp, jderro, jdcode = getoutputerrorsimplecommand(jdposturl, 1)
        if int(jdcode) != 0 or 'FAILURE' in str(jdoutp):
            print('JobDecisionCompleted: Set status of PoleDisk failed', jid)
            sys.exit(0)
        donelist.append(jdone)
    # Done flagging completed jobs
    return donelist

###
# Get the expected count from the DB
def GetExpectedCount(trialdirname):
    #  This checks whether the fragment matches anything in the DB
    gegeturl = copy.deepcopy(basicgeturl)
    gegeturl.append(targetdumpinggetexpected + mangle(trialdirname))
    geoutp, geerro, gecode = getoutputerrorsimplecommand(gegeturl, 1)
    if gecode != 0 or len(geoutp) <= 0:
        return -1
    gejson = json.loads(singletodouble(geoutp))
    try:
        genumber = gejson[0]['number']
    except:
        return -1
    try:
        gen = int(genumber)
    except:
        gen = -1
    return gen
    

###
# Determine whether any of the directories are now full.  Return the
# target directory in question if so
def DirectoryCheckFull(donelist):
    # Each entry in the array is an array with [uuid,slot#,datebegun,poledisk_id,slotname]
    dcok = []
    if len(donelist) <= 0:
        return
    dtargetdir = GiveTarget()
    for packet in donelist:
        # This repeats an earlier disk access!
        dstuff = InventoryOneFull(packet[4])
        for tentativedir in dstuff[1]:
            # It should, in theory not have been full before, and thus
            #  there should not be anything in FullDirectories.  But,
            #  to be on the safe side, check before registering it
            numberexpect = GetExpectedCount(tentativedir)
            if numberexpect < 0:
                print('DirectoryCheckFull has nothing for', tentativedir)
                continue
            dtarg = dtargetdir + '/' + tentativedir
            if CountFilesInDir(dtarg, numberexpect):
                dcok.append(dtarg)
                dcposturl = copy.deepcopy(basicposturl)
                dcposturl.append(targetdumpingenteredreadydir + mangle(dtarg))
                dcoutp, dcerro, dccode = getoutputerrorsimplecommand(geposturl, 1)
                if dccode != 0 or 'FAILURE' in str(dcoutp):
                    print('DirectoryCheckFull could not load', dtarg)
                    continue
    return

###
# Load

####
# Decide whether a new job is needed, or whether an old job is done
#  Do some cleanup too
def JobDecision(dumperstatus, dumpnextAction):
    # Inspect what's out there
    expected, candidate, matching, notmatched = JobInspectAll()
    # Sanity check
    if len(expected) < len(candidate):
        print('JobDecision: we have more jobs running than expected!', len(expected), len(candidate))
        sys.exit(0)
    #
    # Check on completed jobs
    donelist = JobDecisionCompleted(notmatched)
    #
    # Now look through the completed list and see what needs doing with
    # the directories it loaded.  It will push info into FullDirectories
    DirectoryCheckFull(donelist)
    #
    # Next see how long the current set of jobs has been taking
    for jdrunning in matching:
        dateBegun = datetime.datetime.strptime(str(jdrunning[2]), '%Y-%m-%d %H:%M:%S')
        # Since all the times are local, I can use something simple
        minutes = (datetime.datetime.today() - dateBegun).total_seconds() / 60
        if minutes > DUMPING_TIMEOUT:
            print('JobDecision:  job for', jdrunning[0], 'has run long')
            # Don't bail, this might be OK
    #
    # What should we be doing?
    if dumpnextAction == 'Pause' or dumperstatus == 'Idle':
        return
    #
    # See if the jobcount is low enough to let me add another dump
    if len(candidate) >= DUMPING_LIMIT:
        return
    #
    # Got room for another...
    if not CheckLogSpace():
        print('JobDecision:  log space running short')
        return
    # Pick up the next one
    jdgeturl = copy.deepcopy(basicgeturl)
    jdgeturl.append(targetdumpinggetwaiting)
    jdoutp, jderro, jdcode = getoutputerrorsimplecommand(jdgeturl, 1)
    if int(jdcode) != 0 or 'FAILURE' in str(jdoutp):
        print('Get next undone disk failed', jdoutp)
        sys.exit(0)
    if len(jdoutp) <= 0:
        return		# Nothing left to do here
    my_json = json.loads(singletodouble(jdoutp))
    try:
        juuid = my_json[0]['diskuuid']
        jid = my_json[0]['poledisk_id']
        slotnumber = my_json[0]['slotnumber']
    except:
        print('JobDecision:  cannot unpack next disk', my_json)
        sys.exit(0)
    #
    #commandx = ['/usr/bin/cp', DUMPING_SCRIPTS + 'dumpscript', DUMPING_LOG_SPACE + 'DUMPING_' + str(juuid)]
    commandx = ['/bin/cp', DUMPING_SCRIPTS + 'dumpscript', DUMPING_LOG_SPACE + 'DUMPING_' + str(juuid)]
    xoutp, xerro, xcode = getoutputerrorsimplecommand(commandx, 1)
    if int(xcode) != 0:
        print('JobDecision: failed to copy to new script')
        sys.exit(0)
    jdgeturl = copy.deepcopy(basicgeturl)
    jdgeturl.append(targetdumpingslotcontents)
    jdoutp, jderro, jdcode = getoutputerrorsimplecommand(jdgeturl, 1)
    if int(jdcode) != 0:
        print('JobDecision: SlotContents failure', jdgeturl, jdoutp)
        sys.exit(0)
    sl_json = json.loads(singletodouble(jdoutp))
    for js in sl_json:
        if js['slotnumber'] == slotnumber:
            slotlocation = js['name']
            break
    returnstuff = InventoryOneFull(slotlocation)
    targetdir = GiveTarget()
    dirstoscan = returnstuff[1]
    commandy = [DUMPING_SCRIPTS + 'submitdumper', DUMPING_LOG_SPACE + 'DUMPING_' + str(juuid)]
    for source in dirstoscan:
        commandy.append(slotlocation + '/' + source)
        # Create the target directory...
        reducedsource = os.path.dirname(source)
        commandy.append(targetdir + '/' + reducedsource)
    youtp, yerro, ycode = getoutputerrorsimplecommand(commandy, 1)
    if int(ycode) != 0:
        print('JobDecision: submitdumper failed ')
        sys.exit(0)
    #
    # Update PoleDisk info
    jdposturl = copy.deepcopy(basicposturl)
    jdposturl.append(targetdumpingpolediskstart + mangle(str(jid)))
    jdoutp, jderro, jdcode = getoutputerrorsimplecommand(jdposturl, 1)
    if int(jdcode) != 0 or 'FAILURE' in str(jdoutp):
        print('JobDecision:  update PoleDisk w/ start time failed', jdoutp)
        sys.exit(0)
    # If we're running in DumpOne mode, Pause 
    if dumpnextAction == 'DumpOne':
        jdposturl = copy.deepcopy(basicposturl)
        jdposturl.append(targetdumpingstatus + mangle('Pause'))
        jdoutp, jderro, jdcode = getoutputerrorsimplecommand(jdposturl, 1)
        if int(jdcode) != 0 or 'FAILURE' in str(jdoutp):
            print('JobDecision:  update Dumper status failed', jdoutp)
            sys.exit(0)
    #
    #
    return

####
# Decisions
def DumperTodo():
    dtgeturl = copy.deepcopy(basicgeturl)
    dtgeturl.append(targetdumpingstate)
    dtoutp, dterro, dtcode = getoutputerrorsimplecommand(dtgeturl, 1)
    if int(dtcode) != 0 or 'FAILURE' in str(dtoutp):
        print('Get Dumper state failed', dtoutp)
        sys.exit(0)
    # status, nextAction
    dump_json = json.loads(singletodouble(dtoutp))
    status = dump_json[0]['status']
    nextAction = dump_json[0]['nextAction']
    return status, nextAction
#DumperStatusOptions = ['Idle', 'Dumping', 'Inventorying', 'Error']
#DumperNextOptions = ['Dump', 'Pause', 'DumpOne', 'Inventory']

###########
# MAIN
#
# Should we be active at all?
#  Note that Pause still lets us check whether old jobs have completed.
dumpstatus, dumpNextAction = DumperTodo()
if dumpNextAction == 'Inventory':
    # Do not start dumping immediately after inventory!
    InventoryAll()
    mposturl = copy.deepcopy(basicposturl)
    mposturl.append(targetdumpingstate + mangle('Idle'))
    moutp, merro, mcode = getoutputerrorsimplecommand(mposturl, 1)
    if int(mcode) != 0 or 'FAILURE' in str(moutp):
        print('Set Idle Dumper status failed', moutp)
        sys.exit(0)
    mposturl = copy.deepcopy(basicposturl)
    mposturl.append(targetdumpingnext + mangle('Pause'))
    moutp, merro, mcode = getoutputerrorsimplecommand(mposturl, 1)
    if int(mcode) != 0 or 'FAILURE' in str(moutp):
        print('Set Idle Dumper status failed', moutp)
        sys.exit(0)

# Note that the Idle status still allows us to check whether old
# jobs have completed.
if dumpstatus == 'Error' or dumpstatus == 'Inventorying':
    sys.exit(0)

if dumpNextAction == 'Dump' and dumpstatus == 'Idle':
    mposturl = copy.deepcopy(basicposturl)
    mposturl.append(targetdumpingstatus + mangle('Dumping'))
    moutp, merro, mcode = getoutputerrorsimplecommand(mposturl, 1)
    if int(mcode) != 0 or 'FAILURE' in str(moutp):
        print('Set new Dumper status failed', moutp)
        sys.exit(0)
    dumpstatus = 'Dumping'

jobinformation = JobInspectAll()
JobDecision(dumpstatus, dumpNextAction)
